---
title: "36663 Project Part 2"
author: "Mengran He"
date: '`r format(Sys.time(), "%d %B, %Y")`'
output: pdf_document 
geometry: margin=1.5cm
---
```{r, include=FALSE}
library(knitr) # We need the knitr package to set chunk options
library(lme4)
library(xtable)
library(plotrix)
library(MASS)
library(LMERConvenienceFunctions)
library(RLRsim)
library(arm)
library(R2jags)
library(rube)
# Set default knitr options for knitting code into the report:
opts_chunk$set(echo=TRUE,  # change to FALSE to keep code out of the knitted document
               cache=TRUE, # do not re-run code that has already been run
               autodep=TRUE, # assure that caching dependencies are updated correctly
               cache.comments=FALSE, # do not re-run a chunk if only comments are changed
               message=FALSE, # change to FALSE to keep messages out of the knitted document
               warning=FALSE  # change to FALSE to keep warnings out of the knitted document
               )
```

#1. Response variable `reacTime`
**1(a)** In hierarchical linear models, the errors $\epsilon_i$ and random effects $\eta_j$ are normally distributed with mean 0 and variance $\sigma^2$ and $\tau^2$ respectively, because response variable $Y = X\beta + \epsilon$, the response variable also follows normal distribution in linear models. In this dataset, as shown in figure 1a, there are 8169 out of 8257 instances having reaction time less than 10 seconds, so the distribution of reaction time is very right skewed instead of bell shape. On the contrary, from figure 1b, the distribution of log of reaction time across 8257 instances is unimodal, which is more suitable to use as response variable for hierarchical linear model with normal errors and normal random effects.

```{r figure1, fig.cap = 'a) Histogram of reaction time, b) Log of reaction time', echo = FALSE, fig.height = 3, fig.width = 7, message = NA, comment = NA}
dtf <- read.csv("dec-data.csv", header = TRUE)
dtf$SID <- as.factor(dtf$SID)
dtf$currentQuestion <- as.factor(dtf$currentQuestion)
#414 players, 20 unique quesitons
dtf$lrt <- log(dtf$reacTime) #log of reaction time
par(mfrow = c(1,2))
hist(dtf$reacTime, xlab = "reaction time (in seconds)",  breaks = 10, ylim = c(0, 7100), main = "Histogram of reaction time", cex.main = 0.8, cex.lab = 0.8)
hist(dtf$lrt, xlab = "Log of reaction time", main = "Histogram of log of reaction time", cex.main = 0.8, cex.lab = 0.8, ylim = c(0, 3100))
```

**1(b) I** If player's reaction time exceeds 10 seconds the time limit, his answer which is considered as wrong answer will be coded as `resp` = 0 and `higType`= "Time Out!!". However, 250 instances whose reaction time is within time limit range were coded as wrong answer. So, the time limit doesn't strictly adhere to the data. 

**1(b) II** Based on Derek Lomas' hypothesis, larger time limits might increase both success and engagement, so the time limit might had effect on player's reaction time. However, 250 instances didn't strictly adhere to the time limit, which might affect the accuracy of our linear model. For linear models, because the errors are generated by time limit and they can't be explained by the model, the variance of residuals may not be equal and there might be outliers in residual plots. 

**1(b) III** According to Derek Lomas' paper, they tested 8 different time limits: 2, 3, 4, 5, 8, 10, 15 and 30 seconds (ship targets included an additional 5 seconds). In this dataset, the time limit is consistently 10 seconds, so we assumed that those 250 instances were from experiment with shorter time limits. In addition, for `reacTime` variable, the maximum value is 46.605 seconds with `hitType` = "Time Out!!", so we also assumed that this instance was from other experiment with longer time limit 30 seconds. Therefore, for consistency reason, we should remove instances which have `hitType` equal "Time Out!!" but `reacTime` less than 10 seconds or equal to 46.605 seconds. 

```{r part1b, echo = FALSE, message = NA, comment = NA}
#part i
timeout <- dtf[which(dtf$hitType == "Time Out!!" & dtf$reacTime <= 10),]
#part iii
dtf_cl <- subset(dtf, !(X %in% timeout$X)) 
dtf_cl <- dtf_cl[which(dtf_cl$reacTime < 46),] #cleaned dataset
dtf_cl$sid <- as.numeric(as.character(dtf_cl$SID))
dtf_cl$sid <- as.factor(dtf_cl$sid)
```

#2. Ordinary linear regression for question effects
**2(a)** Fitting the linear model without the intercept means that each estimated coefficient is exactly the log of geometric mean of reaction time for each question. As we can see from table 1 that the estimated coefficients of all question types are statistically significant. Figure 2 shows the 95% confidence interval plot for 20 question effects on log of reaction time. From figure 2, we can see that question 0.16 and 0.8 have higher estimated coefficients, which means the reaction time of these two group is longer than other question groups. The geometric mean of reaction time is 3.2415 (=$e^{1.17603}$) seconds  for question 0.16, the geometric mean of reaction time is 3.2093 (=$e^{1.16606}$) seconds for question 0.8, while the geometric mean of reaction time is 2.7829 seconds for question 0.83. 

```{r table1, echo = FALSE, results = 'asis', message = NA, comment = NA}
model1 <- lm(lrt ~ currentQuestion - 1, data = dtf_cl)
options(xtable.comment = FALSE)
xtable(summary(model1), caption = "Summary of ordinary linear model")
```

```{r figure2, fig.cap = 'Plot of 95% confidence interval for each estimated coefficient in model 1', echo = FALSE, fig.height = 3, fig.width = 6, message = NA, comment = NA}
#http://www.ats.ucla.edu/stat/mult_pkg/faq/general/log_transformed_regression.htm
est1 <- coef(summary(model1))
beta1 <- est1[,1]
err <- est1[,2]
question <- sort(unique(dtf_cl$currentQuestion))
plotCI(1:20, beta1, 2*err, gap = 0.02, axes = F, main = "Confidence Interval for question effects", xlab = "Types of question", cex.main = 0.8, cex.lab = 0.8)
box()
axis(2)
axis(1, at = question, labels = question, tick = TRUE, cex.axis=0.6)
```

The diagnostic plots of `model1` in figure 3 shows that model 1 doesn't fit data very well. There are patterns in residuals vs fitted values plot and scale-location plot, and points on residuals' QQplot deviate from the normality assumption line a lot. So this linear model violates normaliy assumption and equal variance assumption. 

```{r figure3, fig.cap = 'Diagnostic plots of model 1', echo = FALSE, fig.height = 2, fig.width = 8, message = NA, comment = NA}
par(mfrow = c(1,4))
plot(model1)
```

**2(b)** The scatter plot of coefficients vs item easiness shows nearly horizontal positive regression line, indicating that the coefficients and item easiness has slightly positive relationship. The scatter plot of coefficients vs mean reaction time on each question shows a positively linear relationship as shown in figure 4a. The scatter plot of coefficients vs log of mean reaction time in figure 4b also suggests a positively linear relationship. The scatter plot of coefficients vs the target value of each question shows no linear relationship. By calculation, the correlation of $\hat{\beta}$ and mean reaction time, correlation of $\hat{\beta}$ and log of mean reaction time are both 0.83. 

```{r figure4, fig.cap = 'a)Coefficients vs Mean of reaction time, b) Coefficients vs Log of mean reaction time', echo = FALSE, fig.height = 3, fig.width = 8, message = NA, comment = NA}
prop.correct <- as.numeric(with(dtf_cl, tapply(resp, currentQuestion, FUN = function(x) sum(x)/length(x))))
#coefficients vs item easiness
# plot(beta1 ~ prop.correct, xlab = "Proportion of players who answer correctly", ylab = "Coefficients of question types", main = "Coefficients vs Item easiness", cex.main = 0.8, cex.lab = 0.8, pch = 18)
# abline(reg = lm(beta1 ~ prop.correct), col = "red")

#coefficients vs the mean of all reaction times on this questions
avgreacTime <- sapply(split(dtf_cl$reacTime, dtf_cl$currentQuestion), mean)
#coefficients vs log of the mean reaction time on this quesiton
log.avgreactime <- log(avgreacTime)
par(mfrow = c(1,2))
plot(beta1 ~ avgreacTime, xlab = "mean of reaction times for each question", ylab = "Coefficients of question types", main = "Coefficients vs Mean of reaction time",cex.main = 0.8, cex.lab = 0.8, pch = 18)
abline(reg = lm(beta1 ~ avgreacTime), col = "red")
plot(beta1 ~ log.avgreactime, xlab = "Log of mean reaction time for each question", ylab = "Coefficients of question types", main = "Coefficients vs Log of mean reaction time",cex.main = 0.8, cex.lab = 0.8, pch = 18)
abline(reg = lm(beta1 ~ log.avgreactime), col = "red")

#coefficients vs the target value for this question
# plot(beta1 ~ sort(as.numeric(as.character(unique(dtf_cl$currentQuestion)))), xlab = "Target value of each question", ylab = "Coefficients of question types", main = "Coefficients vs Target Value of question", cex.main = 0.8, cex.lab = 0.8, pch = 18)
# abline(reg = lm(beta1 ~ sort(as.numeric(unique(dtf_cl$currentQuestion)))), col = "red") 

# coeftable <- cbind(question = sort(as.numeric(as.character(unique(dtf_cl$currentQuestion)))), coefficient = beta1, prop.correct, avgreacTime,log.avgreactime)
# cor(coeftable)
```

**2(c) I** The stepwise and forward model selection are used in automatic variable selection by comparing AIC of each model. The smallest model is ```lm(lrt ~ currentQuestion - 1)``` and largest model is ```lm(lrt ~resp + experimentName + levelName + isGuidesEnabled + currentQuestion + avgAccuracy + avgTime + bestTime + fireType + sound + currentStarCount)```. According to automated model selection, both methods chose the same model, which is ```model1_best: lm(lrt ~ currentQuestion + avgTime + avgAccuracy + bestTime + levelName + currentStarCount + experimentName + fireType - 1)```. 

**2(c) II** The summary of model `model1_best` is in appendix II. The estimated coefficients of 20 question types are all statistically significant as their P-values are less than 0.001. Question 0.16 has largest coefficient -0.7685, among 20 questions, which means the reaction time of question 0.16 is longer than reaction time of other questions. The smallest coefficient of question types is from question 0.83 where estimated coefficient = -0.9094, which means the reaction time of question 0.83 is shortest among 20 questions. `avgTime`, `avgAccuracy`, and `bestTime` are statistically significant, they have significant positive effects on the log of reaction time. We would expect the reaction time to increase 20%, 0.5% and 10.48% when there is one unit increase in `avgTime`, `avgAccuracy`, `bestTime` respectively. For `levelName` variable, there are 4 out of 7 levels not statistically significant, others have significantly negative effects on the log of reaction time. The coefficient of `currentStarCount` is positively related to the log of reaction time. There are 2 out of 15 levels of `experimentName` not statisticaly significant in this model, other levels have significantly positive effects on the log of reaction time. In addition, `fireType` = "CLICK" is also statistically significant, which has positive effect on the log of reaction time, so we would expect the reaction time to increase by 40% when player shifts from using keyboard to mouse click.

```{r echo = FALSE, include = FALSE, message = NA, comment = NA}
# vars.for.varsel <- scan(what = "")
# lrt
# resp
# experimentName
# levelName
# isGuidesEnabled
# currentQuestion
# avgAccuracy
# avgTime
# bestTime
# fireType
# sound
# currentStarCount
# varsel.data <- cbind(dtf_cl[,vars.for.varsel])
# upper.formula <- as.formula(paste(" ~ ",paste(names(varsel.data)[-1], collapse="+")))
# stepAIC(model1,scope=list(lower= ~ currentQuestion - 1, upper = upper.formula), direction="both")
# stepAIC(model1,scope=list(lower= ~ currentQuestion - 1, upper = upper.formula), direction="forward")
model1_best <- lm(lrt ~ currentQuestion + avgTime + avgAccuracy + bestTime + levelName + currentStarCount + experimentName + fireType - 1, data = dtf_cl)
```

**2(c) III** `resp` is an indicator variable, 1 for correct answer, 0 for wrong answer, if `resp` becomes continuous from 0 to 1, they can no longer represent if the response is correct or not, so it doesn't make sense to expain its relationship with `lrt`. For variable `easiness` which measures the proportion of players attempting the item who got it right (`resp` = 1), while the response variable in the linear model is log of reactime time for each player, `easiness` can't be simply fitted in the ordinary linear model because variable length differ, but it can be fitted in multilevel model where `easiness` is in the second level. For variable `currentQuestion` where the numbers ("0.1",  "0.13", "0.16", "0.2",  "0.25", "0.3",  "0.33", "0.38", "0.4",  "0.43", "0.5",  "0.6",  "0.63", "0.66", "0.7",  "0.75", "0.8",  "0.83", "0.88", "0.9") represent the type of questions, if `currentQuestion` is continuous variable, the relationship between `currentQuestion` and `lrt` is explained by the change of the numbers. Nevertheless, the research doesn't indicate the meaning of name of questions, so the relationship between `lrt` and numeric `currentQuestion` doesn't make sense either.


#3. Ordinary linear regression for player effects
**3(a)** After data cleaning in previous step, we have 407 unique player id. ```model2: lm(lrt ~ SID - 1)``` is linear regression model for player effect. There are 407 estimated coefficients representing the expected value of log of reaction time for 407 players. Figure 5 shows the histogram of coefficients of `model2`, over half of `SID` have coefficients between 1 and 1.5, which means the geomeric mean of reaction time of over half of players is between 2.718 and 4.482 seconds. The maximum value of estimated coefficient is 2.347 corresponding to 10.45 seconds of reaction time. The minimum value of estimated coefficient is -1.146 corresponding to 0.32 seconds of reaction time. Among 407 `SID` player effects, nearly 90% of them are statistically significant. The diagnostic plot indicates that there are clear patterns in residuals vs fitted values plot and scale-location plot and points on the left tail of residuals' QQplot deviate from the straight line due to logarithms transformation.

```{r figure5, fig.cap = 'Histogram of estimated coefficient of model 2 and diagnostic plots of model 2', echo = FALSE, fig.height = 4, fig.width = 7, message = NA, comment = NA}
model2 <- lm(lrt ~ sid - 1, data = dtf_cl)
par(mfrow = c(2,3))
hist(coef(model2),ylim = c(0, 300), xlim = c(-2, 3), nclass = 10, xlab = "Coefficient of model 2", main = "Histogram of estimated coefficient of model 2", cex.main = 0.8, cex.lab = 0.8)
#calculate proportion of significant coefficient
significanceModel2 <- ifelse(summary(model2)$coefficients[,4] < 0.05, 1, 0)
#sum(significanceModel2)/length(significanceModel2) 0.8992629
plot(model2)
```

**3b** The scatter plot of coefficients against proportion correct doesn't identify any linear relationship, some points are lined up vertically. The scatter plot of coefficients against player random effects from model `glmer.resp <- glmer(resp ~ currentQuestion - 1 + (1|SID), family = binomial)` has positively linear relationship but slope is very flat. The scatter plot of coefficients vs mean reaction time of each player in figure 6a has inverted U shape, their correlation is 0.8879, so their relationship may not be linear. The scatter plot of coefficients vs log of mean reaction time for each play has perfectly positive linear trend, as shown in figure 6b, and their correlation is 0.9363842. Clearly, the estimated coefficients in `model2` are estimates of the log of mean reaction time for each player. 

```{r figure6, fig.cap = 'a) coefficients vs mean reaction time of player, b) coefficients vs log of mean reaction time of player', echo = FALSE, fig.height = 3, fig.width = 7, message = NA, comment = NA}
beta2 <- coef(model2)
propcorrect_player  <- sapply(split(dtf_cl$resp, dtf_cl$sid), function(x) sum(x)/length(x))
# plot(beta2 ~ propcorrect_player)
# abline(reg = lm(beta2 ~ propcorrect_player), col = "red")

glmer.resp <- glmer(resp ~ currentQuestion -1 + (1|sid), data = dtf_cl, family = "binomial")
ranef_player <- ranef(glmer.resp)$sid[,1]
# plot(beta2 ~ ranef_player)
# abline(reg = lm(beta2 ~ ranef_player), col = "red")
par(mfrow = c(1,2))
reac_player <- sapply(split(dtf_cl$reacTime, dtf_cl$sid), mean)
plot(beta2 ~ reac_player, xlab = "Mena reaction time of each player", ylab = "Coefficients", main = "Coefficients of model 2 vs mean reaction time", cex.main = 0.7, cex.lab = 0.8)
abline(reg = lm(beta2 ~ reac_player), col = "red")
plot(beta2 ~ log(reac_player),xlab = "Log of mean reaction time of each player", ylab = "Coefficients", main = "Coefficients of model 2 vs log(mean reaction time)", cex.main = 0.7, cex.lab = 0.8)
abline(reg = lm(beta2 ~ log(reac_player)), col = "red")
#cor(beta2, reac_player) #0.8879
#cor(beta2, log(reac_player)) #0.9363842
try <- data.frame(cbind(beta2, exponential = exp(beta2), truelog = log(reac_player)))
```

#4. Mixed effects models
**4(a)** The mixed effects model ```model_mix: lmer(lrt ~ currentQuestion + (1|sid) - 1)``` took questions as fixed effects and players as random effects. Table 2 shows that the effects of all questions are statistically significant, among which question 0.16 has largest effects on the log of reaction time and question 0.83 has smallest effects on the log of reaction time, their effects on the log of reaction time are consistent with effects of previous ordinary linear model. Player would take longer reaction time on question 0.16 than doing other questions. From figure 7a, we can see that the values of coefficients mainly concentrate in rage of 1.10 to 1.15. For mixed effect linear model, the residuals and random effects should follow normal distribution with mean 0. Figure 7b and 7c suggest that the QQplots of random effects and residuals of model `model_mix` support normality assumption, except that points on left tails of both QQplots deviate from the straight line. Figure 7d shows that there is a fan shape pattern in residuals vs fitted value plot, maybe it is because of time limit. 

```{r table2, echo = FALSE, results = 'asis', message = NA, comment = NA, warning = FALSE}
model_mix <- lmer(lrt ~ currentQuestion + (1|sid) - 1, data = dtf_cl)
options(xtable.comment = FALSE)
xtable(summary(model_mix)$coefficients, caption = "Summary of mixed effects model")
```

```{r figure7, fig.cap = 'a) Histogram of coefficients of questions as fixed effects, b) QQplot of random effects, c) QQplot of residuals', echo = FALSE, fig.height = 2, fig.width = 8, message = NA, comment = NA}
par(mfrow = c(1,4))
hist(summary(model_mix)$coefficients[,1], xlim = c(1.04, 1.25), nclass = 15, xlab = "Coefficients of mixed effects model", main = "Coefficients of questions as fixed effects", cex.main = 0.8, cex.lab = 0.8)
qqnorm(ranef(model_mix)$sid[,1], main = "Random effects' QQplot", cex.main = 0.8, cex.lab = 0.8)
qqline(ranef(model_mix)$sid[,1])
qqnorm(summary(model_mix)$residuals, main = "Residuals QQplot", cex.main = 0.8, cex.lab = 0.8)
qqline(summary(model_mix)$residuals)
plot(predict(model_mix), resid(model_mix), main = "Residuals vs fitted value", xlab = "Fitted value", ylab = "Residuals", cex.main = 0.8, cex.lab = 0.8)
```

**4(b) I** The largest model I considered was ```full.lmer: lmer(lrt ~ resp + experimentName + levelName + isGuidesEnabled + currentQuestion + avgAccuracy + avgTime + bestTime + fireType + sound + currentStarCount + (1|SID) + (1|ip3) - 1)``` and the smallest model was ```lmer(lrt ~ currentQuestion + (1 | SID) - 1)```. 

For automatic model selection, `fitLMER.fnc()` function in `LMERConvenienceFunctions` library was used to automate backwards selection of fixed effects and forward selection of random effects with BIC method. The full model without intercept is ```full.lmer: lmer(lrt ~ resp + experimentName + levelName + isGuidesEnabled + currentQuestion + avgAccuracy + avgTime + bestTime + fireType + sound + currentStarCount + (1|SID) + (1|ip3) - 1)```, which considered `SID` and `ip3` as random effects. Because ip2 and ip3 gave the same groups, so we only tried one of them. After `fitLMER.fnc()` model selection, the best model was ```bic.best: lmer(lrt ~ isGuidesEnabled + avgAccuracy + avgTime + bestTime + currentStarCount + (1 | SID) + (1 | ip3) - 1)```, which kept both `SID` and `ip3` as random effects. Then, `exactRLRT()` function in `RLRsim` library was used to test random effect of `ip3`. The result of Exact test shows RLRT = 1.1317, p-value = 0.1239, so we didn't reject the null: no random effect for `ip3` in the model.

```{r echo = FALSE, eval = FALSE}
full.lmer <- lmer(lrt ~ resp + experimentName + levelName + isGuidesEnabled + currentQuestion + avgAccuracy + avgTime + bestTime + fireType + sound + currentStarCount + (1|sid) + (1|ip3) - 1, data = dtf_cl)

bic.best <- fitLMER.fnc(full.lmer, ran.effects = c("(1|sid)", "(1|ip3)"), method = "BIC")
bic.noip3 <- lmer(lrt ~ isGuidesEnabled + avgAccuracy + avgTime + bestTime + currentStarCount + (1 | sid) - 1, data = dtf_cl)

#ip2 and ip3 give the same groups, so we will only try one of them: testing random effects for ip3,RLRT = 1.1317, p-value = 0.1239. don't reject the null --> no random effect for ip3
m0 <- lmer(lrt ~ isGuidesEnabled + avgAccuracy + avgTime + bestTime + currentStarCount + (1 | sid) -1, data = dtf_cl)
lmer.ip3.only <- lmer(lrt ~ isGuidesEnabled + avgAccuracy + avgTime + bestTime + currentStarCount + (1|ip3) - 1, data = dtf_cl)
exactRLRT(lmer.ip3.only, bic.best, m0)
```

**4(b) II** Our research mainly focus on questions as fixed effects and players as random effect, we should include `currentQuestion` into the model we just chosen, so the final model is ```final.lmer: lmer(lrt ~ currentQuestion + isGuidesEnabled + avgAccuracy + avgTime + bestTime + currentStarCount + (1 | sid) - 1)```. The summary of fixed effects of `final.lmer` is shown in appendix II, all of fixed effects are statistically significant. In particular, the reaction time is expected to increase 19.13% for one unit increase in `avgTime`, and the reaction time is expected to increase 5.05% if guide is enabled. In figure 8a and 8b, the QQplots of residuals and random effects indicate that the points on lower left tail deviating from straigt line, maybe because of logarithms transformation on response variable. We still found pattern in residuals vs fitted value plot in figure 8c.

```{r figure8, fig.cap = 'a) Random effects QQplot, b)Residuals QQplot, c)Residuals vs fitted values', echo = FALSE, fig.height = 3, fig.width = 7, message = NA, comment = NA}
final.lmer <- lmer(lrt ~ currentQuestion + isGuidesEnabled + avgAccuracy + avgTime + bestTime + currentStarCount+ (1 | sid) - 1, data = dtf_cl)
par(mfrow = c(1,3))
qqnorm(ranef(final.lmer)$sid[,1], main = "Random effects'QQplot", cex.main = 0.8, cex.lab = 0.8)
qqline(ranef(final.lmer)$sid[,1])
qqnorm(summary(final.lmer)$residuals, main = "Residuals QQplot", cex.main = 0.8, cex.lab = 0.8)
qqline(summary(final.lmer)$residuals)
plot(predict(final.lmer), resid(final.lmer), main = "Residuals vs fitted values", xlab = "Fitted value", ylab = "Residuals", cex.main = 0.8, cex.lab = 0.8)
```

#5. Models combining reaction time and correctness of response.
**5(a)** As shown in figure 9a, the item easiness and the mean reaction time of each question has some positive linear relationship based on the instances collected, it suggests that the eaiser the quesiton is, the longer the reaction time. According to Derek Lomas's paper, they measured player engagement by duration of total time played (sum of reaction times across estimates), and they concluded that if the game is easy, player is more willing to engage in the time which results in longer reaction time. Figure 9b suggests that the reaction time of player doesn't depend on the correct rate of player. There are lots of points lined up at porportion correct = 0, it suggests that proportion correct rate of player is 0, the average reaction time of player varies from 0 to more than 10 seconds. When player's proportion correct is 0.5, the average reaction time varies from 0 to about 6 seconds. Moreover, model ```glmer.reac: glmer(resp ~ reacTime - 1 + (1|sid))``` suggests that for 10% increase in reaction time, the probablity of correct response is expected to decrease by 1.4%. In figure 9c the plot of predicted probability of correct response vs reaction time, we can see that given the increase of reaction time, the probability of correct response slightly decreases but doesn't change much. There is a spike at 10 seconds because of time limit. Therefore, we concluded that when question gets harder to answer correctly, the reaction time of player doesn't go up very much, but if the question gets easier, the reaction time gets longer due to player's engagement to the game. 

```{r figure9, fig.cap = 'a) Item easiness vs average reaction time of questions, b) Proportion correct vs average reaction time of players, c) Expected probability of correct response vs reaction time', echo = FALSE, fig.height = 2, fig.width = 8, message = NA, comment = NA}
par(mfrow = c(1,3))
#proportion correct for each question (easiness) vs avg reaction time for each question (reaction time): the eaiser the game, the longer the reaction time is, because engagement is measured by duration of total time played (sum of reaction times across estimates).
plot(avgreacTime ~ prop.correct, xlab = "Item easiness", ylab = "Mean of all reaction times on this question", main = "Item easiness vs average reaction time of questions", cex.main = 0.8, cex.lab = 0.8)
abline(reg = lm(avgreacTime ~ prop.correct), col = "red")

#proportion correct for each player vs average reaction time for each player: the reaction time of each player doesn't depend on the correct rate of player. 
plot(reac_player ~ propcorrect_player, xlab = "Proportion correct for each player", ylab = "Mean reaction time of each player", main = "Proportion correct vs average reaction time of players", cex.main = 0.8, cex.lab = 0.8)
abline(reg = lm(reac_player ~ propcorrect_player), col = "red")

#glmer.react model, sid as random effect: for 10% increase in reaction time, the probablity of correct response is expected to decrease by 1.4%.
glmer.reac <- glmer(resp ~ reacTime - 1 + (1|sid), data = dtf_cl, family = "binomial")
#The plot shows that given the increase of reaction time, the probablity of correct response slightly decreases but doesn't change much. There is a spike at 10 seconds because of time limit.  
plot(dtf_cl$reacTime, predict(glmer.reac, type = "response"), xlab = "Reaction time", ylab = "Expected probability of correct response", main = "Expected probability of correct response vs reaction time", cex.main = 0.8, cex.lab = 0.8)
```

**5(b) I** We fitted a linear regression model ```linden.lm: lm(lrt ~ lp)```, as shown in appendix II, the summary of `linden.lm`. The intercept and the predictor `lp` are statistically significant as the p-values are less than 0.001. The coefficient of `lp` is positive, suggesting that `lp` and `lrt` has positively linear relationship. In figure 10, the diagnostic plots suggest that there are many negative residuals and some outliers in the model, but residuals are independent from fitted values in general. Residuals QQplot shows long negative tails due to logarithms transformation, the scale-location plot support the equal variance assumption. However, from the scatter plot of `lrt` vs `lp` we can see that there are lots of variability, so `lp` alone is not good enough for predicting the log of reaction time. The indication of positive relationship agrees with my previous statement, if the correct response is high, players may be more motivated to play more game, contributing more time to the questions, which may in turn increases reaction time.

```{r figure10, fig.cap = 'diagnostic plots of model linden.lm', echo = FALSE, fig.height = 4, fig.width = 6, message = NA, comment = NA}
lp <- predict(glmer.resp)
linden.lm <- lm(lrt ~ lp, data = dtf_cl)
par(mfrow = c(2,3))
plot(linden.lm, which = c(1:3))
plot(dtf_cl$lrt ~ lp, xlab = "Logit of correct response probability", ylab = "Log of reaction time", main = "Scatter plot of lrt against lp", cex.main = 0.8, cex.lab = 0.8)
abline(reg = lm(dtf_cl$lrt ~ lp), col = "red")
plot(lp, resid(linden.lm), xlab = "logits of correct response probability", ylab = "Residuals", main = "Residuals vs lp")
```

**5(b) II** We applied stepwise and backward automatic model selection on full model ```linden.full: lm(lrt ~ lp + currentQuestion + avgAccuracy + avgTime + bestTime)``` by measuing AIC, and the model selection methods produce the same model```linden.aic: lrt ~ lm(lp + currentQuestion + avgAccuracy + avgTime + bestTime)```. Figure 11 shows the diagnostic plots of model `linden.aic`, by comparing with initial model `linden.lm`, we can see that the residuals are indenpendent from fitted values and covariates in `linden.aic`, and residuals variance tend to be equal. Although the residual QQplot still has heavy tail on the lower left, it is due to log transformation where overfitting might exists, but in general `linden.aic` is better than `linden.lm`. The summary of `linden.aic` shown in appendix II indicates that covariates `lp`, `avgAccuracy`, `avgTime`, `bestTime` are statistically significant. For one unit increase in logit of success probability `lp`, `lrt` is expected to increase by 2.64%, for one unit increase in `avgAccuracy`, `lrt` is expected to increase by 0.56%, for one unit increase in `avgTime`, `lrt` is expected to increase by 20.5%, for one unit increase in `bestTime`, `lrt` is expected to increase by 8.62%. For `currentQuestion`, there are 3 out of 20 quesitons are statistically significant. 

```{r figure11, fig.cap = 'Diagnostic plots of model linden.aic', echo = FALSE, fig.height = 2, fig.width = 7, message = NA, comment = NA}
linden.full <- lm(lrt ~ lp + currentQuestion + avgAccuracy + avgTime + bestTime, data = dtf_cl)
#both and backward produce same model: lrt ~ lp + currentQuestion + avgAccuracy + avgTime + bestTime
#stepAIC(linden.full, scope = list(lower = ~ lp), direction = "both")
linden.aic <- lm(lrt ~ lp + currentQuestion + avgAccuracy + avgTime + bestTime, data = dtf_cl)
par(mfrow = c(1,4))
plot(linden.aic, which = c(1:3))
plot(lp, resid(linden.aic), xlab = "logits of correct response probability", ylab = "Residuals", main = "Residuals vs lp")
```


&nbsp;

**5(c) I ** 
\begin{center}
Level 1: $lrt = \rho lp_{j[i]} + \epsilon_i$, $\epsilon_i \sim N(0, \sigma^2)$

$lp_j = \beta_j currentQuestion_j + \alpha_{l[j]}player_j$

Level 2: $\alpha_l = \beta_0 + \eta_l$, $\eta_l \sim N(0, \tau^2)$
\end{center} 

**5(c) II A** For model `joint.mcmc.0`, $\tau^2$ has `Rhat` = 47.1, indicating that the Markov Chain hasn't converged to its stationary distribution. Also, from the ACF plot, there are lots of spikes along the lag, indicating the autocorrelation exists. Same problems exist in $\beta_0$ and $\beta_j$, and for $\alpha_l$, the autocorrelation problem is most serious. Because `joint.mcmc.0` doesn't produce convergent stationary distribution, it is not reliable to account them as posterior distribution. For model `joint.mcmc.1`, the Markov Chain converges to its stationary distribution, as the parameters don't have autocorrelation, and three chains for each estimate are on top of each other, `Rhat` for all estimates are close to 1, which is good indication of convergence, so the estimates from `joint.mcmc.1` are useful and reliable. 

**5(c) II B** The difference is setup of initial values. For `joint.mcmc.0`, initial values of `bb`, `rho`, and `b0` have mean 0 and variance 1, and initial values for $\tau$ and $\sigma$ are chosen between 0 to 1 from uniform distribution. For `joint.mcmc.1`, the estimates' initial values are chosen from the posterior of `joint.mcmc.0`. The initial values are the initial state of Markov Chain and they will drift to the posterior distribution after many iterations. If the initial values are so different from the posterior distribution, we need more to make Markov Chains converge. `joint.mcmc.1` has initial values closer to posterior, making Markov Chains easily converging to stationary distribution.

```{r table3, echo = FALSE, results = 'asis', message = NA, comment = NA, warning = FALSE}
load("fitted-mcmc.RData")
#p3(joint.mcmc.0)
#p3(joint.mcmc.1)
twoSE <- summary(joint.mcmc.1)$summary[,2]*2
mcmc <- data.frame(cbind(summary(joint.mcmc.1)$summary[, 1:2], twoSE))
mcmc$significance <- as.integer(ifelse(abs(summary(joint.mcmc.1)$summary[,1]) > twoSE, 1, 0))
options(xtable.comment = FALSE)
xtable(mcmc, caption = "Summary of joint.mcmc.1 (significance = 1 if absolute value of mean is greater than 2*SE)", digits = 4)
```

**5(c) III** The summary of estimates of model `joint.mcmc.1` are in table 3, where the fixed effects and random effects for generating `lp` are included, the mean estimated coefficient of `lp` is -1.2608 and the mean estimaed intercept is -0.9406, and they are both statistically significant in this model. For one unit increase in the logit of success probability `lp`, the log of reaction time `lrt` is expected to decrease by 1.26, indicating the negative linear relationship, so if the probability of answering correctly increases, the reaction time tends to decrease. On the other hand, model in part b(i) `linden.lm` suggests a positive relationship between `lrt` and `lp` with estimated coefficient of `lp` = 0.1218, intercept = 1.2351. The conclusion in these two models are different. 

\newpage
#Appendix I
1. Lomas, Derek, Kishan Patel, Jodi L. Forlizzi, and Kenneth R. Koedinger. "Optimizing Challenge in an Educational Game Using Large-scale Design Experiments." Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13 (2013): n. pag. Web.

2. Gelman, Andrew, and Jennifer Hill. Data Analysis Using Regression and Multilevel/hierarchical Models. Cambridge: Cambridge UP, 2007. 

\newpage
#Appendix II
```{r table4, echo = FALSE, results = 'asis', message = NA, comment = NA, warning = FALSE}
#Q4(b)
options(xtable.comment = FALSE)
xtable(summary(final.lmer)$coefficients, caption = "Summary of fixed in final.lmer model in Q4 part b")
```

```{r table5, echo = FALSE, results = 'asis', message = NA, comment = NA, warning = FALSE}
#Q5(b i)initial model summary
options(xtable.comment = FALSE)
xtable(summary(linden.lm)$coefficients, caption = "Summary of linear model lrt ~ lp in Q5 part b(i)")
```

```{r table6, echo = FALSE, results = 'asis', message = NA, comment = NA, warning = FALSE}
#Q5(b ii) aic model summary
options(xtable.comment = FALSE)
xtable(summary(linden.aic)$coefficients, caption = "Summary of linear model in Q5 part b(ii)")
```

```{r table7, echo = FALSE, results = 'asis', message = NA, comment = NA, warning = FALSE}
#Q2(c)
options(xtable.comment = FALSE)
xtable(summary(model1_best), caption = "Summary of best model after automated model selection in Q2 part c")
```





